---
title: Implementation & Testing
pagetitle: Implementation & Testing
section: Playbook
theme: playbook
---

<div class="container pt-5" data-bs-spy="scroll" data-bs-target="#playbook_menu" data-bs-offset="200">

  <div class="row">
    <div class="col-md-3">
      <%= partial "partials/playbook_menu" %>  
    </div>
  
    <div id="content" class="col-md-9">
      <h1>Track 4. Implementation & Testing</h1>
      <p class="lead">Health data standards must be implemented into software systems and workflows to provide a potentially-valuable new or enhanced function in the health ecosystem. Assessing the potential for real value requires testing, including pilots in increasingly realistic settings.</p>

      <p>Both the implementation and testing can surface the need for updates to the Use Case (concept, workflow), standards, and/or software.
      There are other significant biproducts of this Implementation & Testing track.  For example, it’s an opportunity to ensure the necessary Community members are actively involved within increasingly realistic environments. It’s an opportunity to attract new, critical organizations, based by demonstrating potential value, rather than just asserting potential value.
      For Implementation & Testing to progress effectively, activities and necessary resources must be included thoughtfully in the Use Case plans, and prepared for as the Use Case initiative moves forward.</p>
      <p>
      The rest of this section covers experience gained in (a) Implementation, (b) Testing, and (c) Feedback into the previously-discussed Use Case & Planning and Standards Development tracks.
      </p>
      <hr>
      <h2 id="implement_workflows">Implement FHIR IG(s) into Systems and Workflows</h2>
      <p>Every Use Case requires implementing at least part of a FHIR IG into software to support generally new aspects of the envisioned workflow to be piloted. It’s highly recommended to engage market-leading software vendors in the specialty space. Vendors typically have prior experience testing, a customer base that may be interested in new approaches, and credibility that will attract others. Candidate vendors should be engaged in the Community and committed to implement and test (and more) as early in the Use Case project as possible.</p>
      <p>If in the early phases engaging leading vendors is not possible, implementation into prototypes and/or testing software may be a satisfactory first step to allow useful assessments.</p>
      <p>Questions that should be addressed during Implementation include:</p>
      <ul>
      	<li>Is the IG understandable based on technical specifications and documentation?</li>
      	<li>Is the IG implementable?</li>
      	<li>Is the system within which the IG is implemented consistent and interoperable with other systems with which data exchange would be needed?</li>
      	<li>Is the workflow represented within the Use Case and IG realistic and consistent from the developer perspective (will also need user input during testing)?</li>
      </ul>
      <p>In all cases, it’s critical to receive specific comments and recommendations for change that can be taken back to the FHIR IG and the Use Case and Planning teams so that adjustments can be considered - adjustments that could be very helpful before testing becomes intense.</p>
      <hr>
      <h2 id="execute_pilots">Test and Pilot</h2>
      <p>Testing and pilots within Use Cases tend to start simply and then ramp up to as realistic a scenario as possible, via multiple phases. Testing of the implemented IG should start as early as possible, even if on a subset of the future functionality. </p>
      <p>The following table is a simplified set of testing axes that aim for a higher degree of realistic challenges from the top of the table to the bottom.  A particular test or pilot might combine components from different rows, and not just across a single row. </p>

      <%= partial "partials/example_options" %>

      <p>Note that the use of real patient data (bottom row) involves patient and institutional consent, appropriate human protections, and should be planned for many months before testing aims to start.</p>
<p>Early testing provides early feedback and engages key Community members in activities that bring the Use Case concept and IG closer to life. </p>
      <p>However, the CodeX Use Cases have found it useful to start with very simple tests that can be started in 6-12 months after start of the project, including components similar to the first row in the table above. Over time, CodeX Use Cases typically ramp up through increasingly ambitious tests to real-world pilots including components similar to the bottom row: e.g., demonstrating the full Use Case workflow, using software systems intended for sale or otherwise deployed, using real patient data, driven by the intended users, and within many organizations across which the future Use Case is planned to operate. See the <%= link_to("Radiation Therapy Treatment Data Case Study","https://codex-hl7-fhir-accelerator.github.io/playbook/casestudies/radiation_therapy.html") %> for a good example of planning and ramping up of testing.</p>
      <p>
      Obviously, these real-world types of real-world pilot require substantial planning, commitment, preparation, and execution, well in advance of the execution of the pilot. This advanced planning is particularly important for testing in real healthcare settings, using real patient data, etc.
      </p>

      <p>For each of the tests and pilots, considerations typically include the elements below.  These elements should be nearly finalized when initial planning is complete, especially the commitment of the necessary resources.</p>

      <ul class="action-list">
        <li>Objectives 
          <ul>
            <li>What improvements in health care and/or research does the Use Case aim to provide that will be assessed?  (e.g., What will be made better, faster, less expensive, more accessible, etc.?)</li>
          </ul>
        </li>
        <li>Test Configuration
          <ul>
            <li>What parts of the Use Case workflow are being tested, and where are they being tested?</li>
          </ul>
        </li>
        <li>Resources
          <ul>
            <li>Skill sets (e.g., project management, clinical, technical, logistics, legal, operational, etc.)</li>
          	<li>Software (e.g., EHRs, specialty systems, etc.)</li>
          	<li>Facilities (e.g., health system, labs, homes, registries, etc.)</li>
          	<li>Funding (e.g., for facilities, expertise, etc.)</li>
          </ul>
        </li>
        <li>Success
          <ul>
            <li>What metrics are available to assess current capabilities?</li>
            <li>What level of improvement will be measured during the test?</li>
            <li>How will success be measured?</li>
          </ul>
        </li>
      </ul>
      <hr>
      <h2 id="use_feedback">Feedback to Update Previous Work, As Needed</h2>
      <p>Even early phase pilots can provide salient feedback on the implementability of the IG in software, the usability of the updated systems, and the costs, human burden, and potential benefits of the new workflow. Both implementation and testing can surface the need for updates to the Use Case (concept, workflow), standards, and/or software. A test or pilot may need to be repeated, once these updates are agreed and implemented.</p>

    <div class="playbook-bottom-navigation">
        <div class="previous">  <%= link_to("Prev: Standards Development", "standards.html", :class=>"btn btn-outline-primary btn-lg") %></div>
        <div class="next"><%= link_to("Next: Adoption & Value", "adoption.html", :class=>"btn btn-outline-primary btn-lg") %></div>
      </div>
    </div>
  </div>
</div>
